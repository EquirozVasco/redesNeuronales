{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problema: Clasificación de Imágenes de Aves de India\n",
    "\n",
    "Se tiene un data set que contiene 15.000 imágenes de aves comunes de India, las cuales se dividen en 25 categorías distintas (600 imágenes cada categoría). Adicionalmente, cada categoría se ha dividido en 2 grupos donde 550 imágenes pertenecen a `/train` y 50 imágenes pertenencen a `/valid`. Es decir que de las 15.000 imágenes 13.750 son para entrenamiento y 1250 para validacion.\n",
    "\n",
    "Se desea realizar una red neuronal que permita clasificar estas 25 especies de aves y para ello, utilice la técnica de Transferencia de Aprendizaje (Transfer Learning) para utilizar una red previamente entrenada y desarrollar un nuevo modelo.\n",
    "\n",
    "Las imágenes y el modelo entrenado se encuentran en el siguiente link: https://drive.google.com/drive/folders/1p35rHHzd3jahMoY5hh1l-tA_AHI2PXG_?usp=sharing\n",
    "\n",
    "\n",
    "\n",
    "Este archivo contiene la siguiente estructura\n",
    "\n",
    "- filtered_training_set\n",
    "    - train\n",
    "        - Asian Green Bee-Eater\n",
    "        - Brown-Headed Barbet\n",
    "        - **...**\n",
    "        - White-Breasted Waterhen\n",
    "    - valid\n",
    "        - Asian Green Bee-Eater\n",
    "        - Brown-Headed Barbet\n",
    "        - **...**\n",
    "        - White-Breasted Waterhen\n",
    "        \n",
    "Las categorías de cada imagen se encuentran según la carpeta donde estén alojadas las imágenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El modelo que usaremos para la transferencia de aprendizaje es: InceptionV3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iniciamos con el procesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib, os, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Activation, BatchNormalization, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path de dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'filtered_training_set/train'  \n",
    "val_dir = 'filtered_training_set/valid'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generador de imágenes (entrenamiento y validación)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13750 images belonging to 25 classes.\n",
      "Found 1250 images belonging to 25 classes.\n"
     ]
    }
   ],
   "source": [
    "# Rescale\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "valid_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "# data transfer from directories to batches\n",
    "train_data = train_datagen.flow_from_directory(directory = train_dir,\n",
    "                                               batch_size= 32,\n",
    "                                               target_size= (224,224),\n",
    "                                               class_mode = \"categorical\")\n",
    "\n",
    "val_data = valid_datagen.flow_from_directory(directory = val_dir,\n",
    "                                               batch_size = 32,\n",
    "                                               target_size = (224,224),\n",
    "                                               class_mode = \"categorical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instancia del modelo base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "430/430 [==============================] - 771s 2s/step - loss: 1.7988 - accuracy: 0.7263 - val_loss: 2.0553 - val_accuracy: 0.7094\n",
      "Epoch 2/10\n",
      "430/430 [==============================] - 826s 2s/step - loss: 1.2646 - accuracy: 0.8285 - val_loss: 1.8785 - val_accuracy: 0.8031\n",
      "Epoch 3/10\n",
      "430/430 [==============================] - 875s 2s/step - loss: 1.0537 - accuracy: 0.8563 - val_loss: 2.0060 - val_accuracy: 0.7937\n",
      "Epoch 4/10\n",
      "430/430 [==============================] - 875s 2s/step - loss: 0.8737 - accuracy: 0.8841 - val_loss: 1.7840 - val_accuracy: 0.8438\n",
      "Epoch 5/10\n",
      "430/430 [==============================] - 909s 2s/step - loss: 0.8074 - accuracy: 0.8943 - val_loss: 3.3281 - val_accuracy: 0.8000\n",
      "Epoch 6/10\n",
      "430/430 [==============================] - 910s 2s/step - loss: 0.8549 - accuracy: 0.8969 - val_loss: 2.5517 - val_accuracy: 0.8094\n",
      "Epoch 7/10\n",
      "430/430 [==============================] - 912s 2s/step - loss: 0.6285 - accuracy: 0.9173 - val_loss: 2.8645 - val_accuracy: 0.8344\n",
      "Epoch 8/10\n",
      "430/430 [==============================] - 907s 2s/step - loss: 0.5603 - accuracy: 0.9279 - val_loss: 3.0484 - val_accuracy: 0.8125\n",
      "Epoch 9/10\n",
      "430/430 [==============================] - 914s 2s/step - loss: 0.6218 - accuracy: 0.9223 - val_loss: 3.0139 - val_accuracy: 0.8125\n",
      "Epoch 10/10\n",
      "430/430 [==============================] - 845s 2s/step - loss: 0.4865 - accuracy: 0.9369 - val_loss: 2.8940 - val_accuracy: 0.8562\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.InceptionV3(include_top= False,input_shape=(224, 224, 3))\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape =(224, 224,3), name = \"input-layer\")\n",
    "\n",
    "x = base_model(inputs)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D(name = \"global_average_pooling_layer\")(x)\n",
    "outputs = tf.keras.layers.Dense(25, activation = \"softmax\", name = \"output-layer\")(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = tf.keras.optimizers.Adam(learning_rate = 0.01), metrics = [\"accuracy\"])\n",
    "\n",
    "history = model.fit(train_data,\n",
    "                                 epochs=10,\n",
    "                                 steps_per_epoch = len(train_data),\n",
    "                                 validation_data = val_data,\n",
    "                                 validation_steps = int(0.25*len(val_data)),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input-layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " inception_v3 (Functional)   (None, 5, 5, 2048)        21802784  \n",
      "                                                                 \n",
      " global_average_pooling_laye  (None, 2048)             0         \n",
      " r (GlobalAveragePooling2D)                                      \n",
      "                                                                 \n",
      " output-layer (Dense)        (None, 25)                51225     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,854,009\n",
      "Trainable params: 51,225\n",
      "Non-trainable params: 21,802,784\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congelamiento de los top layers para Fine-Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1 False\n",
      "1 conv2d False\n",
      "2 batch_normalization False\n",
      "3 activation False\n",
      "4 conv2d_1 False\n",
      "5 batch_normalization_1 False\n",
      "6 activation_1 False\n",
      "7 conv2d_2 False\n",
      "8 batch_normalization_2 False\n",
      "9 activation_2 False\n",
      "10 max_pooling2d False\n",
      "11 conv2d_3 False\n",
      "12 batch_normalization_3 False\n",
      "13 activation_3 False\n",
      "14 conv2d_4 False\n",
      "15 batch_normalization_4 False\n",
      "16 activation_4 False\n",
      "17 max_pooling2d_1 False\n",
      "18 conv2d_8 False\n",
      "19 batch_normalization_8 False\n",
      "20 activation_8 False\n",
      "21 conv2d_6 False\n",
      "22 conv2d_9 False\n",
      "23 batch_normalization_6 False\n",
      "24 batch_normalization_9 False\n",
      "25 activation_6 False\n",
      "26 activation_9 False\n",
      "27 average_pooling2d False\n",
      "28 conv2d_5 False\n",
      "29 conv2d_7 False\n",
      "30 conv2d_10 False\n",
      "31 conv2d_11 False\n",
      "32 batch_normalization_5 False\n",
      "33 batch_normalization_7 False\n",
      "34 batch_normalization_10 False\n",
      "35 batch_normalization_11 False\n",
      "36 activation_5 False\n",
      "37 activation_7 False\n",
      "38 activation_10 False\n",
      "39 activation_11 False\n",
      "40 mixed0 False\n",
      "41 conv2d_15 False\n",
      "42 batch_normalization_15 False\n",
      "43 activation_15 False\n",
      "44 conv2d_13 False\n",
      "45 conv2d_16 False\n",
      "46 batch_normalization_13 False\n",
      "47 batch_normalization_16 False\n",
      "48 activation_13 False\n",
      "49 activation_16 False\n",
      "50 average_pooling2d_1 False\n",
      "51 conv2d_12 False\n",
      "52 conv2d_14 False\n",
      "53 conv2d_17 False\n",
      "54 conv2d_18 False\n",
      "55 batch_normalization_12 False\n",
      "56 batch_normalization_14 False\n",
      "57 batch_normalization_17 False\n",
      "58 batch_normalization_18 False\n",
      "59 activation_12 False\n",
      "60 activation_14 False\n",
      "61 activation_17 False\n",
      "62 activation_18 False\n",
      "63 mixed1 False\n",
      "64 conv2d_22 False\n",
      "65 batch_normalization_22 False\n",
      "66 activation_22 False\n",
      "67 conv2d_20 False\n",
      "68 conv2d_23 False\n",
      "69 batch_normalization_20 False\n",
      "70 batch_normalization_23 False\n",
      "71 activation_20 False\n",
      "72 activation_23 False\n",
      "73 average_pooling2d_2 False\n",
      "74 conv2d_19 False\n",
      "75 conv2d_21 False\n",
      "76 conv2d_24 False\n",
      "77 conv2d_25 False\n",
      "78 batch_normalization_19 False\n",
      "79 batch_normalization_21 False\n",
      "80 batch_normalization_24 False\n",
      "81 batch_normalization_25 False\n",
      "82 activation_19 False\n",
      "83 activation_21 False\n",
      "84 activation_24 False\n",
      "85 activation_25 False\n",
      "86 mixed2 False\n",
      "87 conv2d_27 False\n",
      "88 batch_normalization_27 False\n",
      "89 activation_27 False\n",
      "90 conv2d_28 False\n",
      "91 batch_normalization_28 False\n",
      "92 activation_28 False\n",
      "93 conv2d_26 False\n",
      "94 conv2d_29 False\n",
      "95 batch_normalization_26 False\n",
      "96 batch_normalization_29 False\n",
      "97 activation_26 False\n",
      "98 activation_29 False\n",
      "99 max_pooling2d_2 False\n",
      "100 mixed3 False\n",
      "101 conv2d_34 False\n",
      "102 batch_normalization_34 False\n",
      "103 activation_34 False\n",
      "104 conv2d_35 False\n",
      "105 batch_normalization_35 False\n",
      "106 activation_35 False\n",
      "107 conv2d_31 False\n",
      "108 conv2d_36 False\n",
      "109 batch_normalization_31 False\n",
      "110 batch_normalization_36 False\n",
      "111 activation_31 False\n",
      "112 activation_36 False\n",
      "113 conv2d_32 False\n",
      "114 conv2d_37 False\n",
      "115 batch_normalization_32 False\n",
      "116 batch_normalization_37 False\n",
      "117 activation_32 False\n",
      "118 activation_37 False\n",
      "119 average_pooling2d_3 False\n",
      "120 conv2d_30 False\n",
      "121 conv2d_33 False\n",
      "122 conv2d_38 False\n",
      "123 conv2d_39 False\n",
      "124 batch_normalization_30 False\n",
      "125 batch_normalization_33 False\n",
      "126 batch_normalization_38 False\n",
      "127 batch_normalization_39 False\n",
      "128 activation_30 False\n",
      "129 activation_33 False\n",
      "130 activation_38 False\n",
      "131 activation_39 False\n",
      "132 mixed4 False\n",
      "133 conv2d_44 False\n",
      "134 batch_normalization_44 False\n",
      "135 activation_44 False\n",
      "136 conv2d_45 False\n",
      "137 batch_normalization_45 False\n",
      "138 activation_45 False\n",
      "139 conv2d_41 False\n",
      "140 conv2d_46 False\n",
      "141 batch_normalization_41 False\n",
      "142 batch_normalization_46 False\n",
      "143 activation_41 False\n",
      "144 activation_46 False\n",
      "145 conv2d_42 False\n",
      "146 conv2d_47 False\n",
      "147 batch_normalization_42 False\n",
      "148 batch_normalization_47 False\n",
      "149 activation_42 False\n",
      "150 activation_47 False\n",
      "151 average_pooling2d_4 False\n",
      "152 conv2d_40 False\n",
      "153 conv2d_43 False\n",
      "154 conv2d_48 False\n",
      "155 conv2d_49 False\n",
      "156 batch_normalization_40 False\n",
      "157 batch_normalization_43 False\n",
      "158 batch_normalization_48 False\n",
      "159 batch_normalization_49 False\n",
      "160 activation_40 False\n",
      "161 activation_43 False\n",
      "162 activation_48 False\n",
      "163 activation_49 False\n",
      "164 mixed5 False\n",
      "165 conv2d_54 False\n",
      "166 batch_normalization_54 False\n",
      "167 activation_54 False\n",
      "168 conv2d_55 False\n",
      "169 batch_normalization_55 False\n",
      "170 activation_55 False\n",
      "171 conv2d_51 False\n",
      "172 conv2d_56 False\n",
      "173 batch_normalization_51 False\n",
      "174 batch_normalization_56 False\n",
      "175 activation_51 False\n",
      "176 activation_56 False\n",
      "177 conv2d_52 False\n",
      "178 conv2d_57 False\n",
      "179 batch_normalization_52 False\n",
      "180 batch_normalization_57 False\n",
      "181 activation_52 False\n",
      "182 activation_57 False\n",
      "183 average_pooling2d_5 False\n",
      "184 conv2d_50 False\n",
      "185 conv2d_53 False\n",
      "186 conv2d_58 False\n",
      "187 conv2d_59 False\n",
      "188 batch_normalization_50 False\n",
      "189 batch_normalization_53 False\n",
      "190 batch_normalization_58 False\n",
      "191 batch_normalization_59 False\n",
      "192 activation_50 False\n",
      "193 activation_53 False\n",
      "194 activation_58 False\n",
      "195 activation_59 False\n",
      "196 mixed6 False\n",
      "197 conv2d_64 False\n",
      "198 batch_normalization_64 False\n",
      "199 activation_64 False\n",
      "200 conv2d_65 False\n",
      "201 batch_normalization_65 False\n",
      "202 activation_65 False\n",
      "203 conv2d_61 False\n",
      "204 conv2d_66 False\n",
      "205 batch_normalization_61 False\n",
      "206 batch_normalization_66 False\n",
      "207 activation_61 False\n",
      "208 activation_66 False\n",
      "209 conv2d_62 False\n",
      "210 conv2d_67 False\n",
      "211 batch_normalization_62 False\n",
      "212 batch_normalization_67 False\n",
      "213 activation_62 False\n",
      "214 activation_67 False\n",
      "215 average_pooling2d_6 False\n",
      "216 conv2d_60 False\n",
      "217 conv2d_63 False\n",
      "218 conv2d_68 False\n",
      "219 conv2d_69 False\n",
      "220 batch_normalization_60 False\n",
      "221 batch_normalization_63 False\n",
      "222 batch_normalization_68 False\n",
      "223 batch_normalization_69 False\n",
      "224 activation_60 False\n",
      "225 activation_63 False\n",
      "226 activation_68 False\n",
      "227 activation_69 False\n",
      "228 mixed7 False\n",
      "229 conv2d_72 False\n",
      "230 batch_normalization_72 False\n",
      "231 activation_72 False\n",
      "232 conv2d_73 False\n",
      "233 batch_normalization_73 False\n",
      "234 activation_73 False\n",
      "235 conv2d_70 False\n",
      "236 conv2d_74 False\n",
      "237 batch_normalization_70 False\n",
      "238 batch_normalization_74 False\n",
      "239 activation_70 False\n",
      "240 activation_74 False\n",
      "241 conv2d_71 False\n",
      "242 conv2d_75 False\n",
      "243 batch_normalization_71 False\n",
      "244 batch_normalization_75 False\n",
      "245 activation_71 False\n",
      "246 activation_75 False\n",
      "247 max_pooling2d_3 False\n",
      "248 mixed8 False\n",
      "249 conv2d_80 False\n",
      "250 batch_normalization_80 False\n",
      "251 activation_80 False\n",
      "252 conv2d_77 False\n",
      "253 conv2d_81 False\n",
      "254 batch_normalization_77 False\n",
      "255 batch_normalization_81 False\n",
      "256 activation_77 False\n",
      "257 activation_81 False\n",
      "258 conv2d_78 False\n",
      "259 conv2d_79 False\n",
      "260 conv2d_82 False\n",
      "261 conv2d_83 False\n",
      "262 average_pooling2d_7 False\n",
      "263 conv2d_76 False\n",
      "264 batch_normalization_78 False\n",
      "265 batch_normalization_79 False\n",
      "266 batch_normalization_82 False\n",
      "267 batch_normalization_83 False\n",
      "268 conv2d_84 False\n",
      "269 batch_normalization_76 False\n",
      "270 activation_78 False\n",
      "271 activation_79 False\n",
      "272 activation_82 False\n",
      "273 activation_83 False\n",
      "274 batch_normalization_84 False\n",
      "275 activation_76 False\n",
      "276 mixed9_0 False\n",
      "277 concatenate False\n",
      "278 activation_84 False\n",
      "279 mixed9 False\n",
      "280 conv2d_89 False\n",
      "281 batch_normalization_89 False\n",
      "282 activation_89 False\n",
      "283 conv2d_86 False\n",
      "284 conv2d_90 False\n",
      "285 batch_normalization_86 False\n",
      "286 batch_normalization_90 False\n",
      "287 activation_86 False\n",
      "288 activation_90 False\n",
      "289 conv2d_87 False\n",
      "290 conv2d_88 False\n",
      "291 conv2d_91 False\n",
      "292 conv2d_92 False\n",
      "293 average_pooling2d_8 False\n",
      "294 conv2d_85 False\n",
      "295 batch_normalization_87 False\n",
      "296 batch_normalization_88 False\n",
      "297 batch_normalization_91 False\n",
      "298 batch_normalization_92 False\n",
      "299 conv2d_93 False\n",
      "300 batch_normalization_85 False\n",
      "301 activation_87 True\n",
      "302 activation_88 True\n",
      "303 activation_91 True\n",
      "304 activation_92 True\n",
      "305 batch_normalization_93 True\n",
      "306 activation_85 True\n",
      "307 mixed9_1 True\n",
      "308 concatenate_1 True\n",
      "309 activation_93 True\n",
      "310 mixed10 True\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "base_model.trainable = True\n",
    "\n",
    "# Un-freeze last 10 layers\n",
    "for layer in base_model.layers[:-10]:\n",
    "  layer.trainable = False\n",
    "\n",
    "# Recompile (we have to compile model every time there is a change)\n",
    "model.compile(loss = \"categorical_crossentropy\",\n",
    "                optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001), # when fine-tuning you typically want to lower lr by 10x\n",
    "                 metrics = [\"accuracy\"] )\n",
    "\n",
    "for layer_number, layer in enumerate(model.layers[1].layers):\n",
    "  print(layer_number, layer.name, layer.trainable)\n",
    "\n",
    "print(len(model.trainable_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/11\n",
      "430/430 [==============================] - 848s 2s/step - loss: 0.1018 - accuracy: 0.9797 - val_loss: 2.0766 - val_accuracy: 0.8813\n",
      "Epoch 11/11\n",
      "430/430 [==============================] - 824s 2s/step - loss: 0.0481 - accuracy: 0.9882 - val_loss: 2.9486 - val_accuracy: 0.8219\n"
     ]
    }
   ],
   "source": [
    "initial_epochs = 10\n",
    "fine_tune_epochs = initial_epochs + 1\n",
    "history_2 = model.fit(train_data,\n",
    "                       epochs = fine_tune_epochs,\n",
    "                       validation_data = val_data,\n",
    "                       validation_steps = int(0.25*len(val_data)),\n",
    "                       initial_epoch =  history.epoch[-1],) # Start the epoch where it left before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('birdman.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
